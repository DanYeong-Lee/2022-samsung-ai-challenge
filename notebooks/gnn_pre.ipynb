{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.utils.features import (allowable_features, atom_to_feature_vector,\n",
    " bond_to_feature_vector, atom_feature_vector_to_dict, bond_feature_vector_to_dict) \n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "def mol2graph(mol):\n",
    "    \"\"\"\n",
    "    Converts SMILES string to graph Data object\n",
    "    :input: SMILES string (str)\n",
    "    :return: graph object\n",
    "    \"\"\"\n",
    "\n",
    "    # atoms\n",
    "    atom_features_list = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append(atom_to_feature_vector(atom))\n",
    "    x = np.array(atom_features_list, dtype = np.int64)\n",
    "\n",
    "    # bonds\n",
    "    num_bond_features = 3  # bond type, bond stereo, is_conjugated\n",
    "    if len(mol.GetBonds()) > 0: # mol has bonds\n",
    "        edges_list = []\n",
    "        edge_features_list = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "\n",
    "            edge_feature = bond_to_feature_vector(bond)\n",
    "\n",
    "            # add edges in both directions\n",
    "            edges_list.append((i, j))\n",
    "            edge_features_list.append(edge_feature)\n",
    "            edges_list.append((j, i))\n",
    "            edge_features_list.append(edge_feature)\n",
    "\n",
    "        # data.edge_index: Graph connectivity in COO format with shape [2, num_edges]\n",
    "        edge_index = np.array(edges_list, dtype = np.int64).T\n",
    "\n",
    "        # data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features]\n",
    "        edge_attr = np.array(edge_features_list, dtype = np.int64)\n",
    "\n",
    "    else:   # mol has no bonds\n",
    "        edge_index = np.empty((2, 0), dtype = np.int64)\n",
    "        edge_attr = np.empty((0, num_bond_features), dtype = np.int64)\n",
    "\n",
    "    return x, edge_attr, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate_features(mol):\n",
    "    conf = mol.GetConformer()\n",
    "    return conf.GetPositions()\n",
    "\n",
    "def get_mol_data(prefix, y=None):\n",
    "    if prefix.startswith(\"train\"):\n",
    "        what_set = \"train_set\"\n",
    "    else:\n",
    "        what_set = \"test_set\"\n",
    "    ex = Chem.MolFromMolFile(f\"../data/mol_files/{what_set}/{prefix}_ex.mol\", removeHs=False)\n",
    "    g = Chem.MolFromMolFile(f\"../data/mol_files/{what_set}/{prefix}_g.mol\", removeHs=False)\n",
    "    \n",
    "    # Atom features\n",
    "    X, edge_attr, edge_index = mol2graph(ex)\n",
    "    \n",
    "    # Atom 3D coordinates\n",
    "    co_ex = get_coordinate_features(ex)\n",
    "    co_g = get_coordinate_features(g)\n",
    "            \n",
    "    X = np.concatenate([X, co_ex, co_g], axis=1)\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "    \n",
    "    y = torch.tensor([y], dtype=torch.float)\n",
    "            \n",
    "    return Data(x=X, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        \n",
    "\n",
    "def get_dataset(df):\n",
    "    data_list = []\n",
    "    if \"Reorg_g\" in df.columns:\n",
    "        for _, item in tqdm(df.iterrows()):\n",
    "            y = [item.Reorg_g, item.Reorg_ex]\n",
    "            data = get_mol_data(item[0], y)\n",
    "            data_list.append(data)\n",
    "    else:\n",
    "        for _, item in tqdm(df.iterrows()):\n",
    "            data = get_mol_data(item[0])\n",
    "            data_list.append(data)\n",
    "        \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, permitted_list):\n",
    "    \"\"\"\n",
    "    Maps input elements x which are not in the permitted list to the last element\n",
    "    of the permitted list.\n",
    "    \"\"\"\n",
    "\n",
    "    if x not in permitted_list:\n",
    "        x = permitted_list[-1]\n",
    "\n",
    "    binary_encoding = [int(boolean_value) for boolean_value in list(map(lambda s: x == s, permitted_list))]\n",
    "\n",
    "    return binary_encoding\n",
    "\n",
    "def get_atom_features(atom):\n",
    "    \"\"\"\n",
    "    Takes an RDKit atom object as input and gives a 1d-numpy array of atom features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    # define list of permitted atoms\n",
    "    \n",
    "    permitted_list_of_atoms =  ['B', 'Br', 'C', 'Cl', 'F', 'I', 'N', 'O', 'P', 'S', 'Si', \"H\"]\n",
    "    \n",
    "    # compute atom features\n",
    "    \n",
    "    atom_feature_vector = []\n",
    "    \n",
    "    atom_feature_vector += one_hot_encoding(str(atom.GetSymbol()), permitted_list_of_atoms)\n",
    "    \n",
    "    atom_feature_vector += one_hot_encoding(str(atom.GetChiralTag()), [\"CHI_UNSPECIFIED\", \"CHI_TETRAHEDRAL_CW\", \"CHI_TETRAHEDRAL_CCW\", \"CHI_OTHER\"])\n",
    "    \n",
    "    #atom_feature_vector += one_hot_encoding(str(atom.GetHybridization()), [\"S\", \"SP\", \"SP2\", \"SP3\", \"SP3D\", \"SP3D2\", \"OTHER\"])\n",
    "    \n",
    "    #atom_feature_vector += [int(atom.IsInRing())]\n",
    "    \n",
    "    #atom_feature_vector += [int(atom.GetIsAromatic())]\n",
    "\n",
    "    return np.array(atom_feature_vector)\n",
    "\n",
    "\n",
    "def get_bond_features(bond):\n",
    "    \"\"\"\n",
    "    Takes an RDKit bond object as input and gives a 1d-numpy array of bond features as output.\n",
    "    \"\"\"\n",
    "\n",
    "    permitted_list_of_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC]\n",
    "    \n",
    "    bond_feature_vector = []\n",
    "    \n",
    "    bond_feature_vector += one_hot_encoding(bond.GetBondType(), permitted_list_of_bond_types)\n",
    "    \n",
    "    bond_feature_vector += one_hot_encoding(str(bond.GetBondDir()), [\"NONE\", \"ENDUPRIGHT\", \"ENDDOWNRIGHT\"])\n",
    "    \n",
    "    #bond_feature_vector += [int(bond.GetIsConjugated())]\n",
    "    \n",
    "    #bond_feature_vector += [int(bond.IsInRing())]\n",
    "    \n",
    "    #bond_feature_vector += one_hot_encoding(str(bond.GetStereo()), [\"STEREOZ\", \"STEREOE\", \"STEREOANY\", \"STEREONONE\"])\n",
    "\n",
    "    return np.array(bond_feature_vector)\n",
    "\n",
    "def get_node_features(mol):\n",
    "    # get feature dimensions\n",
    "    X = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        X.append(get_atom_features(atom))\n",
    "    \n",
    "    return np.array(X)\n",
    "\n",
    "def get_edge_features(mol):\n",
    "        # get feature dimensions\n",
    "    X = []\n",
    "    for atom in mol.GetBonds():\n",
    "        X.append(get_bond_features(atom))\n",
    "    \n",
    "    return np.array(X)\n",
    "\n",
    "def get_coordinate_features(mol):\n",
    "    conf = mol.GetConformer()\n",
    "    return conf.GetPositions()\n",
    "\n",
    "def get_mol_data(prefix, y=None):\n",
    "    if prefix.startswith(\"train\"):\n",
    "        what_set = \"train_set\"\n",
    "    else:\n",
    "        what_set = \"test_set\"\n",
    "    ex = Chem.MolFromMolFile(f\"../data/mol_files/{what_set}/{prefix}_ex.mol\", removeHs=False)\n",
    "    g = Chem.MolFromMolFile(f\"../data/mol_files/{what_set}/{prefix}_g.mol\", removeHs=False)\n",
    "    \n",
    "    # Atom features\n",
    "    node_X = get_node_features(ex)\n",
    "    \n",
    "    # Atom 3D coordinates\n",
    "    co_ex = get_coordinate_features(ex)\n",
    "    co_g = get_coordinate_features(g)\n",
    "    \n",
    "    # Adjacency matrix\n",
    "    (rows, cols) = np.nonzero(GetAdjacencyMatrix(ex))\n",
    "    torch_rows = torch.from_numpy(rows.astype(np.int64)).to(torch.long)\n",
    "    torch_cols = torch.from_numpy(cols.astype(np.int64)).to(torch.long)\n",
    "    edge_index = torch.stack([torch_rows, torch_cols], dim = 0)\n",
    "    \n",
    "    # Bond features\n",
    "    edge_attr = []\n",
    "\n",
    "    for i, j in zip(rows, cols):\n",
    "        edge_attr.append(get_bond_features(ex.GetBondBetweenAtoms(int(i),int(j))))\n",
    "\n",
    "    edge_attr = torch.tensor(np.array(edge_attr), dtype = torch.float)\n",
    "    \n",
    "    if type(y) != type(None):\n",
    "            y = torch.tensor(np.array([y]), dtype=torch.float)\n",
    "            \n",
    "    X = np.concatenate([node_X, co_ex, co_g], axis=1)\n",
    "    X = torch.tensor(X, dtype=torch.float)\n",
    "            \n",
    "    return Data(x=X, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "        \n",
    "\n",
    "def get_dataset(df):\n",
    "    data_list = []\n",
    "    if \"Reorg_g\" in df.columns:\n",
    "        for _, item in tqdm(df.iterrows()):\n",
    "            y = [item.Reorg_g, item.Reorg_ex]\n",
    "            data = get_mol_data(item[0], y)\n",
    "            data_list.append(data)\n",
    "    else:\n",
    "        for _, item in tqdm(df.iterrows()):\n",
    "            data = get_mol_data(item[0])\n",
    "            data_list.append(data)\n",
    "        \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14525it [00:38, 377.04it/s]\n",
      "1942it [00:04, 391.04it/s]"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/train_set.ReorgE.csv\")\n",
    "test_df = pd.read_csv(\"../data/test_set.csv\")\n",
    "\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = get_dataset(train_df)\n",
    "val_data = get_dataset(val_df)\n",
    "test_data = get_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32, shuffle=False, drop_last=False, num_workers=4, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=False, drop_last=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[1468, 15], edge_index=[32], edge_attr=[32], y=[32], batch=[1468], ptr=[33])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[57, 15], edge_index=[2, 122], edge_attr=[122, 3], y=[2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATNet(nn.Module):\n",
    "    def __init__(self, input_dim=15, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.main = gnn.Sequential(\"x, edge_index, edge_attr, batch\", [\n",
    "            (gnn.GATv2Conv(in_channels=input_dim, out_channels=64, heads=4, edge_dim=7), \"x, edge_index, edge_attr -> x\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "            (gnn.GATv2Conv(in_channels=256, out_channels=64, heads=4, edge_dim=7), \"x, edge_index, edge_attr -> x\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "            (gnn.GATv2Conv(in_channels=256, out_channels=64, heads=4, edge_dim=7), \"x, edge_index, edge_attr -> x\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "            (gnn.global_mean_pool, \"x, batch -> x\"),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, out_dim)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        return self.main(x, edge_index, edge_attr, batch)\n",
    "    \n",
    "class GINNet(nn.Module):\n",
    "    def __init__(self, input_dim=19, out_dim=2):\n",
    "        super().__init__()\n",
    "        self.main = gnn.Sequential(\"x, edge_index, edge_attr, batch\", [\n",
    "            (gnn.GINEConv(nn.Linear(input_dim, 256), edge_dim=7), \"x, edge_index, edge_attr -> x\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "            (gnn.GINEConv(nn.Linear(256, 256), edge_dim=7), \"x, edge_index, edge_attr -> x\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "            (gnn.global_mean_pool, \"x, batch -> x\"),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, out_dim)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        return self.main(x, edge_index, edge_attr, batch)\n",
    "\n",
    "\n",
    "class TwoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net_ex = GATNet()\n",
    "        self.net_g = GATNet()\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        G_e = self.net_g(batch.x_ex, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        G_g = self.net_g(batch.x_g, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        G = G_e - G_g\n",
    "        \n",
    "        E_e = self.net_ex(batch.x_ex, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        E_g = self.net_ex(batch.x_g, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        E = E_g - E_e\n",
    "        \n",
    "        return torch.cat([G, E], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 64.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.20342496080340539\n",
      "Val Loss: 0.11379211395978928\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 63.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.10948931112621738\n",
      "Val Loss: 0.10087671875953674\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 61.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09700299028010495\n",
      "Val Loss: 0.09784424304962158\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 64.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09287589287335894\n",
      "Val Loss: 0.09605482965707779\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 64.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09078152205762083\n",
      "Val Loss: 0.08552774786949158\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 61.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08604284389092859\n",
      "Val Loss: 0.08660633862018585\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 60.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08404391408955629\n",
      "Val Loss: 0.0792718231678009\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 60.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08131421532119269\n",
      "Val Loss: 0.08753850311040878\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 65.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0798107481569843\n",
      "Val Loss: 0.07733990252017975\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 69.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0796310806531558\n",
      "Val Loss: 0.0800861120223999\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 61.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07864695236878058\n",
      "Val Loss: 0.07887125760316849\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 63.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0793935161545477\n",
      "Val Loss: 0.07330000400543213\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 65.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07703827659442888\n",
      "Val Loss: 0.07407233119010925\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 64.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07748670013934637\n",
      "Val Loss: 0.07228431105613708\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 61.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0753069851811217\n",
      "Val Loss: 0.07786265760660172\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 64.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07500791465616331\n",
      "Val Loss: 0.07258640974760056\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 65.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07446256044230103\n",
      "Val Loss: 0.0731412023305893\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 63.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07438242038200914\n",
      "Val Loss: 0.07230972498655319\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 66.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0738449555417869\n",
      "Val Loss: 0.07205026596784592\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 65.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07261720907965065\n",
      "Val Loss: 0.07570961862802505\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 66.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07215696471059217\n",
      "Val Loss: 0.071410171687603\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 65.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07149629553664574\n",
      "Val Loss: 0.07132541388273239\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 66.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07066374127052527\n",
      "Val Loss: 0.0705186203122139\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 63.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07008481304268394\n",
      "Val Loss: 0.06938931345939636\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 65.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06965060098574752\n",
      "Val Loss: 0.06960906088352203\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 63.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06898473714173367\n",
      "Val Loss: 0.06893468648195267\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 64.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06872402996945698\n",
      "Val Loss: 0.06892707198858261\n",
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 66.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06848679591728522\n",
      "Val Loss: 0.06870012730360031\n",
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 64.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06828281240521279\n",
      "Val Loss: 0.06878464668989182\n",
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:03<00:00, 65.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06813607758850651\n",
      "Val Loss: 0.06870730221271515\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "model = GINNet(22, 2)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs * len(train_dataloader))\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_loss, val_loss = 0., 0.\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        loss = criterion(pred, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    # validation\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in val_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        loss = criterion(pred, batch.y)\n",
    "        val_loss += loss * len(batch.y)\n",
    "    \n",
    "    val_loss /= len(val_data)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss}\")\n",
    "    print(f\"Val Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "model.eval()\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch = batch.to(device)\n",
    "    pred = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "    preds.append(pred)\n",
    "\n",
    "preds = torch.cat(preds).detach().cpu().numpy()\n",
    "\n",
    "sub_df = pd.read_csv(\"data/sample_submission.csv\")\n",
    "sub_df[\"Reorg_g\"] = preds[:, 0]\n",
    "sub_df[\"Reorg_ex\"] = preds[:, 1]\n",
    "sub_df.to_csv(\"submission.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mol",
   "language": "python",
   "name": "mol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
